{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio - Exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "Se tienen dos archivos csv “Clientes” y “Servicios” y se requiere saber cuales son los clientes que tienen un servicio y cuales son los \n",
    "clientes que no tienen un servicio asociado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "    NEW BRANCH                    EXISTS                       SINK\n",
    " ________________          ___________________          _____________________        \n",
    "|                |        |                   |        |                     |      \n",
    "|  SourceCliente |--------|  NotExistsCliente |--------| sinkClienteNoExiste |\n",
    "|________________| +      |___________________| +      |_____________________|\n",
    "\n",
    "      SOURCE                      EXISTS                       SINK\n",
    " ________________          ___________________          _____________________        \n",
    "|                |        |                   |        |                     |      \n",
    "|  SourceCliente |--------|   ExistsCliente   |--------|  sinkClienteExiste  |\n",
    "|________________| +      |___________________| +      |_____________________|\n",
    "                                |          \n",
    "      SOURCE                    |\n",
    " ________________               |\n",
    "|                |              |   \n",
    "| SourceServicio |--------------'\n",
    "|________________| "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sourceCliente\n",
    "\n",
    "- Utilizamos \"Inline Dataset\" (obtenemos el mismo resultado que utilizando \"Dataset\", no se cual es la real diferencia)\n",
    "- Inline Dataset Type: escogemos el tipo de archivo de origen\n",
    "- Linked service: escogemos el Linked Service de origen, y este apunta hacia Azure Blob Storage, a una ruta especifica\n",
    "- Debug mode: al activarlo nos permitirá acceder a las opciones de Projection y Data preview\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/JzLTSX8N/adf42.png\"></center>\n",
    "\n",
    "- También activamos la casilla de \"First Row Header\"\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/3RvmKLCd/adf43.png\"></center>\n",
    "\n",
    "- Importamos el schema\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/vZ4BF4vm/adf44.png\"></center>\n",
    "\n",
    "\n",
    "##### sourceServicio\n",
    "\n",
    "- Utilizamos \"Inline Dataset\" \n",
    "- Inline Dataset Type: escogemos el tipo de archivo de origen\n",
    "- Linked service: escogemos el Linked Service de origen, y este apunta hacia Azure Blob Storage, a una ruta especifica\n",
    "- Debug mode: al activarlo nos permitirá acceder a las opciones de Projection y Data preview\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/13V97L9n/adf45.png\"></center>\n",
    "\n",
    "- También activamos la casilla de \"First Row Header\"\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/1zZZCXC2/adf46.png\"></center>\n",
    "\n",
    "- Importamos el schema\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/NFKVfvCR/adf47.png\"></center>\n",
    "\n",
    "- Si revisamos \"Data Preview\" para ver como se visualiza el campo 'date'\n",
    "- Vemos que todos los valores de la columna 'Fecha' aparecen como 'NULL'\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/pXbbXpxT/adf48.png\"></center>\n",
    "\n",
    "- Para un archivo CSV de origen que tiene un campo de fechas del tipo 'date' debemos modificar su tipo \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/SRKXnDc6/adf49.png\"></center>\n",
    "\n",
    "- Si revisamos \"Data Preview\" para ver como se visualiza el campo 'date' con el cambio realizado\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/MKvMx36x/adf50.png\"></center>\n",
    "\n",
    "\n",
    "##### ExistsCliente\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/1RYXW0pd/adf51.png\"></center>\n",
    "\n",
    "\n",
    "##### sinkClienteExiste\n",
    "\n",
    "- Utilizamos \"Inline Dataset\" \n",
    "- Inline Dataset Type: escogemos el tipo de archivo de salida\n",
    "- Linked service: escogemos el Linked Service de destino, y este apunta hacia Azure Blob Storage, a una ruta especifica\n",
    "- Debug mode: al activarlo nos permitirá acceder a las opciones de Mapping y Data preview\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/k4YJp9tS/adf52.png\"></center>\n",
    "\n",
    "- El directorio \"5.Exists\" se creará de manera automática dentro del contenedor \"dataflowdataset\"\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/K8Q8MnvQ/adf53.png\"></center>\n",
    "\n",
    "- No particionamos el archivo y se creará un único archivo llamado \"ClienteExists.csv\". Debemos pulsar sobre\n",
    "  el botón de \"Set single partition\" que aparecerá\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/GhxcWkYr/adf54.png\"></center>\n",
    "\n",
    "\n",
    "##### NotExistsCliente\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/t7QNWKD0/adf55.png\"></center>\n",
    "\n",
    "\n",
    "##### sinkClienteNoExiste\n",
    "\n",
    "- Utilizamos \"Inline Dataset\" \n",
    "- Inline Dataset Type: escogemos el tipo de archivo de salida\n",
    "- Linked service: escogemos el Linked Service de destino, y este apunta hacia Azure Blob Storage, a una ruta especifica\n",
    "- Debug mode: al activarlo nos permitirá acceder a las opciones de Mapping y Data preview\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/3xW2WJ3y/adf56.png\"></center>\n",
    "\n",
    "- El directorio \"5.Exists\" se creará de manera automática dentro del contenedor \"dataflowdataset\"\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/7Yt2v8Sq/adf57.png\"></center>\n",
    "\n",
    "- No particionamos el archivo y se creará un único archivo llamado \"ClienteNotExists.csv\". Debemos pulsar sobre\n",
    "  el botón de \"Set single partition\" que aparecerá\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/zXyfgLR1/adf58.png\"></center>\n",
    "\n",
    "\n",
    "##### Ejecución del Pipeline y resultados\n",
    "\n",
    "- Despues de haber finalizado nuestro Data Flow, lo ejecutaremos dentro de una actividad \"Data Flow\" desde un Pipeline\n",
    "- Podemos ver que se han creado los dos archivos  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/MZQ6ZkkW/adf59.png\"></center>  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
