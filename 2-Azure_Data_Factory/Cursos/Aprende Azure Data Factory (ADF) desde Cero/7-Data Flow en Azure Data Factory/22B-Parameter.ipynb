{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio - Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "Continuando con el desarrollo del ejercicio, se requiere crear \"Parametro\" y ahí pasar el valor.\n",
    "\n",
    "Se requiere exportar el reporte de los \"Empleados\" por su \"Cargo\" y generar un archivo de salida delimitado por comas (CSV).\n",
    " _____________________________________________________________________________________________________________________\n",
    "|                                                                                                                     |  \n",
    "|   Los valores de los parámetros los establece los Pipeline de llamadas a través de la actividad Ejecutar DataFlow   |\n",
    "|_____________________________________________________________________________________________________________________|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "       SOURCE                      FILTER                          SINK                \n",
    " __________________          __________________          _________________________             \n",
    "|                  |        |                  |        |                         |      \n",
    "|  SourceEmpleado  |--------|      Filter      |--------|   sinkReporteEmpleado   |\n",
    "|__________________| +      |__________________| +      |_________________________|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sourceEmpleado\n",
    "\n",
    "- Utilizamos \"Inline Dataset\" (obtenemos el mismo resultado que utilizando \"Dataset\", no se cual es la real diferencia)\n",
    "- Inline Dataset Type: escogemos el tipo de origen\n",
    "- Linked service: escogemos el Linked Service de origen, y este apunta hacia Azure SQL Database, a una base de datos \n",
    "                  especifica\n",
    "- Debug mode: al activarlo nos permitirá acceder a las opciones de Projection y Data preview. También nos permitirá     \n",
    "              visualizar las tablas en Source options\n",
    "\n",
    "- Creamos un Stored Procedure que al ejecutarlo seleccione ciertas columnas\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/WpB83j9T/adf228.png\"></center>\n",
    "\n",
    "- Continuamos con la configuración de nuestra tarea\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/s22SD07p/adf229.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/m2HWKbn9/adf230.png\"></center>\n",
    "\n",
    "- Importamos el schema\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/tJHRMYzB/adf231.png\"></center>\n",
    "\n",
    "\n",
    "##### Filter\n",
    "\n",
    "- Creamos un parámetro para utilizarlo en el filtro\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/hjFhkS83/adf232.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/tTtR8F4Y/adf233.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/QtshgVJs/adf234.png\"></center>\n",
    "\n",
    "- Se genera el filtro de registros\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/Y0s5PSYv/adf235.png\"></center>\n",
    "\n",
    "\n",
    "##### sinkReporteEmpleado\n",
    "\n",
    "- Utilizamos \"Inline Dataset\" (obtenemos el mismo resultado que utilizando \"Dataset\", no se cual es la real diferencia)\n",
    "- Inline Dataset Type: escogemos el tipo de archivo de salida\n",
    "- Linked service: escogemos el Linked Service de destino, y este apunta hacia Azure Blob Storage, a una ruta especifica\n",
    "- Debug mode: al activarlo nos permitirá acceder a las opciones de Mapping y Data preview.\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/jScS8HC2/adf236.png\"></center>\n",
    "\n",
    "- El directorio \"21.Parameter\" se creará de manera automática dentro del contenedor \"dataflowdataset\"\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/gkDx5FTG/adf237.png\"></center>\n",
    "\n",
    "- No particionamos el archivo y se creará un único archivo llamado \"ReporteEmpleado.csv\". Debemos pulsar sobre\n",
    "  el botón de \"Set single partition\" que aparecerá\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/SQVqbSk1/adf238.png\"></center>\n",
    "\n",
    "\n",
    "##### Ejecución del Pipeline y resultados\n",
    "\n",
    "- Despues de haber finalizado nuestro Data Flow, lo ejecutaremos dentro de una actividad \"Data Flow\" desde un Pipeline\n",
    "- Desde la pestaña \"Parameter\" debemos generar un contenido dinámico para el valor del Parámetro\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/wMT4gdgD/adf239.png\"></center> \n",
    "<center><img src=\"https://i.postimg.cc/Rh7K0gL9/adf240.png\"></center> \n",
    "<center><img src=\"https://i.postimg.cc/KcPMBsth/adf241.png\"></center> \n",
    "<center><img src=\"https://i.postimg.cc/28X8Z49f/adf242.png\"></center> \n",
    "<center><img src=\"https://i.postimg.cc/Xqq6jPbB/adf243.png\"></center> \n",
    "<center><img src=\"https://i.postimg.cc/J0GSVBNb/adf244.png\"></center> \n",
    "\n",
    "- El valor del parámetro de esta manera quedará ESTÁTICO. También podriamos dejar vacia esta celda e ingresar un valor\n",
    "  al momento de ejecutar el Pipeline\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/h4NK4SXS/adf245.png\"></center> \n",
    "<center><img src=\"https://i.postimg.cc/cL0y660N/adf246.png\"></center> \n",
    "\n",
    "- Podemos ver que se ha creado el archivo\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/hvBMMzCD/adf247.png\"></center> \n",
    "\n",
    "- Revisamos cuantos registros deberian existir para el filtro que aplicamos a los datos\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/4dzQK4Xr/adf248.png\"></center> "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
