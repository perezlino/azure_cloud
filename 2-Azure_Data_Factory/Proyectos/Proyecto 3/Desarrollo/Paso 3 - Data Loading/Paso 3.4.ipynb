{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Paso 3.3 - Creación de un Pipeline**\n",
    "\n",
    "1. Crear el Pipeline de ingesta de datos **PL_ADLS_to_SQL**, el cual contendrá una actividad **Copy data**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crear el Pipeline de ingesta de datos **PL_ADLS_to_SQL**\n",
    "\n",
    "Utilizamos el comodín ***.parquet** para que solo utilice los archivos de formato **PARQUET** que se encuentran en nuestro dataset de origen, es decir, desde nuestro ADLS, mas especificamente en la ruta **refined/data**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/ncSQQ6r8/adf565.png\"></center>\n",
    "\n",
    "Podemos pre visualizar los datos\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/hvyhTdS8/adf566.png\"></center>\n",
    "\n",
    "Dado que en nuestro dataset de destino utilizamos una tabla que NO EXISTE, ahora debemos indicar en **Sink** la opción de  **AUTO CREATE TABLE**, para que cree de manera automática la tabla. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/FK5zymQ6/adf567.png\"></center>\n",
    "\n",
    "Ahora **Validamos** y ejecutamos nuestro pipeline con la opción **Debug**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/02z7Z8L5/adf568.png\"></center>\n",
    "\n",
    "Si verificamos en SSMS \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/t4XV1WFc/adf569.png\"></center>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
