{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Paso 2.1 - Creamos el Data flow \"df_transform_cases_deaths\" para transformar los datos del archivo \"cases_deaths.csv\"**\n",
    "\n",
    "1. Configurar el stream **Source** y crear un nuevo dataset de origen que haga referencia al archivo **cases_deaths.csv**, llamado  \n",
    "   **df_raw_cases_and_deaths**\n",
    "\n",
    "2. Agregar un stream **Filter** para filtrar el campo **continent** y nos devuelva solo registros para el continente **Europe**\n",
    "\n",
    "3. Agregar un stream **Select** para seleccionar las columnas que necesitamos\n",
    "\n",
    "4. Agregar un stream **Pivot**\n",
    "\n",
    "5. Agregar un stream **Lookup** y un stream **Source**. Además, crear un nuevo dataset de origen que haga referencia al archivo **country_lookup.csv**, llamado **ds_country_lookup**\n",
    "\n",
    "6. Nuevamente, agregar un stream **Select** para seleccionar y ordenar las columnas que necesitamos   \n",
    "\n",
    "7. Y para finalizar, utilizaremos un stream **Sink** y creamos un un nuevo dataset de destino que haga referencia a la ruta **processed/ecdc/cases_deaths** de nuestro ADLS. No se indicó un nombre de archivo\n",
    "\n",
    "8. Creamos un pipeline llamado **pl_process_cases_and_deaths_data*** para ejecutar el Data flow recién creado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "          SOURCE                          FILTER                            SELECT                           PIVOT                      LOOKUP                        SELECT                         SINK\n",
    " ________________________          ____________________          ____________________________          _________________          ___________________          ___________________          _______________________\n",
    "|                        |        |                    |        |                            |        |                 |        |                   |        |                   |        |                       |      \n",
    "|  CasesAndDeathsSource  |--------|  FilterEuropeOnly  |--------|  SelectOnlyRequiredFileds  |--------|   PivotCounts   |--------|   LookupCountry   |--------|   SelectForSink   |--------|   CaseAndDeathsSink   |\n",
    "|________________________| +      |____________________| +      |____________________________| +      |_________________| +      |___________________| +      |___________________| +      |_______________________|\n",
    "                                                                                                                                      |    \n",
    "        SOURCE                                                                                                                        |    \n",
    " ___________________                                                                                                                  |    \n",
    "|                   |-----------------------------------------------------------------------------------------------------------------'    \n",
    "|   CountryLookup   |        \n",
    "|___________________|        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configurar el stream **Source** y crear un nuevo dataset de origen que haga referencia al archivo **cases_deaths.csv**, llamado **df_raw_cases_and_deaths**\n",
    "\n",
    "Creamos un nuevo contenedor **lookup** en ADLS y cargamos el archivo **country_lookup.csv**.\n",
    "\n",
    "Comenzamos configurando nuestro \"stream\" **source** que se llama **CasesAndDeathsSource**. Creamos un nuevo dataset de origen que haga referencia al archivo **cases_deaths.csv**, llamado **df_raw_cases_and_deaths**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/YCYFG4nh/adf781.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/x8BkqYLv/adf782.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/8c7J1sfk/adf783.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/mDX1f7D6/adf784.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/7L42gxdX/adf785.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/bvR2g7jP/adf786.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/zBXHcxJg/adf787.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/gJx5PNPS/adf788.png\"></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agregar un stream **Filter** para filtrar el campo **continent** y nos devuelva solo registros para el continente **Europe**\n",
    "\n",
    "En la opción **Filter on** escribimos la siguiente condición para el filtro:\n",
    "```\n",
    "continent == 'Europe' && not(isNull(country_code))\n",
    "```\n",
    "<center><img src=\"https://i.postimg.cc/s2r7zXdt/adf789.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/QMJ5d3jV/adf790.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/Tw2by4P0/adf791.png\"></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agregar un stream **Select** para seleccionar los campos que necesitamos\n",
    "\n",
    "Primero veamos que nos permite hacer el stream **Select** :\n",
    "\n",
    "```\n",
    "1. Add Mapping --> Fixed mapping\n",
    "```\n",
    "Nos permite duplicar un campo ya existente. Como tenemos la casilla **Skip duplicate input columns** activada, solo se tomará en cuenta la primera columna que encuentre\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/BbL8W8N9/adf792.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/05FMYf28/adf793.png\"></center>\n",
    "\n",
    "```\n",
    "2. Add Mapping --> Rule-based mapping\n",
    "```\n",
    "a) Podemos utilizar **Delete** para borrar todas las columnas y utilizar **Rule-based mapping**, es decir, utilizar expresiones que indiquen que columnas queremos utilizar\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/Nj7Kwv8M/adf794.png\"></center>\n",
    "\n",
    "Podemos hacer uso de **true()** para llamar a TODAS LAS COLUMNAS. Y podemos actualizar el nombre de las columnas anteponiendo **cases_** para cada una de ellas. Para hacer esto usamos la expresión **'cases_' + $$** \n",
    "\n",
    "- Donde **$$** llama al mismo nombre de la columna \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/XqRrnVDZ/adf795.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/8zV73z69/adf796.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/7YzCm2fS/adf797.png\"></center>\n",
    "\n",
    "b) Podemos hacer uso de **type == 'string'** para llamar SOLO A LAS COLUMNAS DE TIPO STRING. Y podemos actualizar el nombre de las columnas utilizando **$$** para que lleve el mismo nombre y termine con la palabra **_string** \n",
    "\n",
    "- Por tanto, utilizamos la expresión **$$ + '_string'**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/TPthpj4v/adf798.png\"></center>\n",
    "\n",
    "```\n",
    "Transformación real utilizando el stream \"Select\"\n",
    "```\n",
    "Pulsamos **Reset** para volver al estado original de las columnas\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/63TqR7k2/adf799.png\"></center>\n",
    "\n",
    "Eliminamos 3 columnas: **continent**, **rate_14_day** y **date**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/cJxrxkTc/adf800.png\"></center>\n",
    "\n",
    "Luego utilizamos un **Rule-based mapping** para volver a llamar al campo **date** (que habiamos eliminado anteriormente) y le actualizamos su nombre utilizando la expresión **'reported' + '_date'**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/nz5z1Fxd/adf801.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/t7G4LBYW/adf802.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/RhH0skVv/adf803.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/xjct5nML/adf804.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/44qwFqQq/adf805.png\"></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agregar un stream **Pivot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "Esto es lo que realizamos con la tarea PIVOT:\n",
    "\n",
    "1.- Agrupamos columnas \n",
    " _______________________________________________                                       _________________________________________________________________ \n",
    "|country            country_code    population  |    indicator           daily_count  |   reported_date     source                                      |\n",
    "|United Kingdom     GBR             66647112    |    confirmed cases     0            |   2020-01-02        Epidemic intelligence, national daily data  |           \n",
    "|United Kingdom     GBR             66647112    |    deaths              0            |   2020-01-02        Epidemic intelligence, national daily data  |\n",
    "|United Kingdom     GBR             66647112    |    confirmed cases     0            |   2020-01-03        Epidemic intelligence, national daily data  |\n",
    "|United Kingdom     GBR             66647112    |    deaths              0            |   2020-01-03        Epidemic intelligence, national daily data  |\n",
    "|United Kingdom     GBR             66647112    |    confirmed cases     0            |   2020-01-04        Epidemic intelligence, national daily data  |\n",
    "|United Kingdom     GBR             66647112    |    deaths              0            |   2020-01-04        Epidemic intelligence, national daily data  |\n",
    "|_______________________________________________|                                     |_________________________________________________________________|\n",
    "\n",
    "2.- Elegimos una columna PIVOT KEY: indicator\n",
    "\n",
    "3.- Elegimos la(s) columna PIVOTEADA: daily_count\n",
    " __________________________________________________________________________________________________________________________________________________________\n",
    "|country            country_code    population      reported_date     source                                        confirmed cases_count   deaths_count   |                   \n",
    "|United Kingdom     GBR             66647112        2020-01-02        Epidemic intelligence, national daily data    0                       0              | \n",
    "|United Kingdom     GBR             66647112        2020-01-03        Epidemic intelligence, national daily data    0                       0              | \n",
    "|United Kingdom     GBR             66647112        2020-01-04        Epidemic intelligence, national daily data    0                       0              | \n",
    "|__________________________________________________________________________________________________________________________________________________________|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización de los datos que tenemos hasta el momento\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/G2HGFP9G/adf806.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/HxR5BJ7K/adf807.png\"></center>\n",
    "\n",
    "Agrupamos las columnas: **country**, **country_code**, **population**, **source** y **reported_date**. Creamos la columna **country_special** que unirá los valores de las columnas **country** y **country_code** (esta columna es solo de ejemplo, se borarrá al final)\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/ZRBvBTDL/adf808.png\"></center>\n",
    "\n",
    "La columna **Pivot key** sera **indicator**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/ydMg0wMC/adf809.png\"></center>\n",
    "\n",
    "La **columna pivoteada** será **daily_count**. Como **expression prefix** colocamos **count**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/cLhnPknf/adf813.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/wBBmz5XZ/adf814.png\"></center>\n",
    "\n",
    "Previsualizamos lo que llevamos hasta el momento\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/K8xTqhRZ/adf811.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/SKtzxXVs/adf815.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/pXt5rMQD/adf816.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/15cnN7Mb/adf817.png\"></center>\n",
    "\n",
    "Como se comentó al inicio, eliminaremos la columna **country_special**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/DfGb7wGv/adf818.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/yx0JjLKg/adf819.png\"></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agregar un stream **Lookup**\n",
    "\n",
    "Comenzamos creando un nuevo dataset de origen que haga referencia al archivo **country_lookup.csv**, llamado **ds_country_lookup**. Se encuentra en la ruta **lookup/country_lookup.csv**, siendo **lookup** el contenedor\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/gJgLrgp3/adf820.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/kMZDZ6gM/adf821.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/tTv797d5/adf822.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/fRQyzGd6/adf823.png\"></center>\n",
    "\n",
    "En un nuevo stream **Source** llamado **CountryLookup** nos conectamos al dataset recien creado **ds_country_lookup**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/br2Y8gwy/adf824.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/3w7kBsJg/adf825.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/qqtqq0jd/adf826.png\"></center>\n",
    "\n",
    "Agregamos el stream **Lookup** y nos conectamos al stream **Source** : **CountryLookup**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/4nkf3cYz/adf827.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/RhjFn8DJ/adf828.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/sD7S494C/adf829.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/2SYWcb0b/adf830.png\"></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agregar un stream **Select**\n",
    "\n",
    "De esta manera seleccionamos y ordenamos las columnas que vamos a utilizar\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/7h7CXw7n/adf831.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/s26Zgns7/adf832.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/ydD3gF85/adf833.png\"></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregar un stream **Sink**\n",
    "\n",
    "Creamos un nuevo contenedor de nombre **processed** en ADLS\n",
    "\n",
    "Creamos un nuevo dataset de destino **ds_processed_cases_and_deaths** que haga referencia a la ruta **processed/ecdc/cases_deaths**. El directorio **ecdc** y el subdirectorio **cases_deaths** no existen, por lo que se crearan de manera automática. No se indicó un nombre de archivo\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/NGPgN5xs/adf834.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/mDpG65CX/adf835.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/3RxT1T40/adf836.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/MGDw1TT8/adf837.png\"></center>\n",
    "\n",
    "Nos conectamos al dataset recien creado **ds_processed_cases_and_deaths**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/6Qww7RB0/adf838.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/TYLTBfkr/adf839.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/Yq5tHZVT/adf840.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/Z564Kjzn/adf841.png\"></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creamos un pipeline para ejecutar el dataflow\n",
    "\n",
    "Creamos un pipeline llamado **pl_process_cases_and_deaths_data*** para ejecutar el Data flow recién creado\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/tJgv8RpW/adf842.png\"></center>\n",
    "\n",
    "**Validamos**, **Publicamos** y ejecutamos el pipeline utilizando **Debug**. Recordar que no indicamos ningún archivo de salida, por tanto, nos devolverá un archivo con múltiples particiones\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/SRt140x5/adf843.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/63WMG67g/adf844.png\"></center>\n",
    "\n",
    "En la pestaña de **Settings** indicamos que queremos que SEA UN SOLO ARCHIVO DE SALIDA y le damos un nombre al archivo\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/FKgPRkK0/adf845.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/SN31tp5Y/adf846.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/hGqyc1KS/adf847.png\"></center>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
