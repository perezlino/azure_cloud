{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Proyecto 3 - Ingesta, Transformación, Carga y Reportería**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Arquitectura del Proyecto**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/t4j2B2gs/adf455.png\"></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Paso 1 - Data Ingestion**\n",
    "_____\n",
    "\n",
    "1. Pasos a seguir en nuestra Ingesta de datos desde Azure Blob Storage hacia Azure Data Lake Storage Gen2\n",
    "\n",
    "    *   Crear un contenedor en ABS donde almancenar la data\n",
    "    *   Crear un contenedor en ADLS donde almacenar la data\n",
    "    *   Crear Linked Services de origen y destino\n",
    "    *   Crear datasets de origen y destino    \n",
    "    *   Crear un Pipeline de ingesta de datos    \n",
    "\n",
    "\n",
    "<center><img src=\"https://images2.imgbox.com/a7/8b/zClZtz13_o.png\"></center> <!-- adf664 -->\n",
    "\n",
    "2. Pasos a seguir en nuestra Ingesta de datos desde HTTP hacia Azure Data Lake Storage Gen2\n",
    "\n",
    "    *   Reutilizaremos contenedor en ADLS donde almacenar la data\n",
    "    *   Crear un Linked Service de origen y reutilizar el Linked Service de destino\n",
    "    *   Crear datasets parametrizados tanto de origen como destino \n",
    "    *   Crear un Pipeline de ingesta de datos parametrizado    \n",
    "\n",
    "\n",
    "<center><img src=\"https://images2.imgbox.com/3e/19/JBr4g1NM_o.png\"></center> <!-- adf721 -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Paso 1.1 - Creación de Linked Services de origen y destino para la ingesta de datos desde Azure Blob Storage hacia Azure Data Lake Storage Gen2**\n",
    "\n",
    "1. Crear el Linked Service de origen **ls_ablob_covidreportingsa** que hace referencia a Azure Blob Storage\n",
    "\n",
    "2. Crear el Linked Service de destino **ls_adls_covidreportingdl** que hace referencia a nuestro ADLS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Paso 1.2 - Creación de Datasets de origen y destino para la ingesta de datos desde Azure Blob Storage hacia Azure Data Lake Storage Gen2**\n",
    "\n",
    "1. Crear el Dataset de origen **ds_population_raw_gz** que hace referencia al archivo **population_by_age.tsv.gz** alojado en el contenedor **population** en Azure Blob Storage\n",
    "\n",
    "2. Crear el Dataset de destino **ds_population_raw_tsv** que hace referencia al archivo **population_by_age.tsv** (que aún no existe, pero se   \n",
    "   creará de manera automática al ejecutar el pipeline) a nuestro ADLS, a la ruta **raw/population**. Siendo **raw** el contenedor y **population** el directorio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Paso 1.3 - Creación de un Pipeline para la ingesta de datos desde Azure Blob Storage hacia Azure Data Lake Storage Gen2**\n",
    "\n",
    "1. Crear el Pipeline de ingesta de datos **pl_ingest_population_data**, el cual contendrá una actividad **Copy data**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Paso 1.4 - Escenarios extras**\n",
    "\n",
    "1. Ejecutar la actividad **Copy data** cuando el archivo esté disponible\n",
    "\n",
    "2. Ejecutar la actividad **Copy data** sólo si el contenido del archivo es el esperado\n",
    "\n",
    "3. Eliminar el archivo de origen al copiarlo correctamente"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Paso 1.5 - Creación de un Linked Service de origen para la ingesta de datos desde HTTP hacia Azure Data Lake Storage Gen2**\n",
    "\n",
    "1. Crear el Linked Service de origen **ls_http_opendata_ecdc_europa_eu** que hace referencia a HTTP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Paso 1.6 - Creación de Datasets de origen y destino parametrizados para la ingesta de datos desde HTTP hacia Azure Data Lake Storage Gen2**\n",
    "\n",
    "1. Crear el Dataset de origen **ds_ecdc_raw_csv_http** que hace referencia al archivo parametrizado **@dataset().relativeURL**. Dicho valor del   \n",
    "   parámetro será indicado al momento de ejecutar el pipeline\n",
    "\n",
    "2. Crear el Dataset de destino **ds_ecdc_raw_csv_dl** que hace referencia al archivo parametrizado **@dataset().fileName** (que aún no existe,    \n",
    "   pero se creará de manera automática al ejecutar el pipeline) de nuestro ADLS, aque se almacenará en la ruta **raw/ecdc**. Siendo **raw** el contenedor y **ecdc** el directorio"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
