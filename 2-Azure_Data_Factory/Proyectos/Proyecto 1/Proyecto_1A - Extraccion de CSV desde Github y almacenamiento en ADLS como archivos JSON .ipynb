{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Proyecto 1A - Extracción de múltiples archivos CSV desde Github y almacenamiento en ADLS como archivos JSON**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 6 - Crear nuevos dataset, crear un nuevo Pipeline y agregar la actividad \"Lookup\"\n",
    "\n",
    "17. Una forma mucho más eficiente de trabajar con múltiples archivos es utilizando **PARÁMETROS**.\n",
    "    Para ello trabajaremos solo con 2 datasets, uno de origen y de destino y crearemos dos \n",
    "    parámetros, ambos a nivel de dataset, uno en cada dataset.\n",
    "\n",
    "    Añadiremos un parámetro para el archivo **ds_Source_IPL_2008_json** que es el archivo que\n",
    "    utilizaremos como dataset de destino para todos los archivos. Más adelante modificaremos\n",
    "    su nombre\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/KvJP6N2V/adf280.png\"></center> \n",
    "<center><img src=\"https://i.postimg.cc/sx242VtY/adf281.png\"></center>\n",
    "\n",
    "Añadiremos un parámetro para el archivo **ds_Source_IPL_2008_csv** que es el archivo que\n",
    "utilizaremos como dataset de origen para todos los archivos. Más adelante modificaremos\n",
    "su nombre\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/DzKQXQ9y/adf282.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/SK76724L/adf283.png\"></center>\n",
    "\n",
    "18. Modificamos los nombres de nuestros dataset de origen y destino. Quedarán de la siguiente \n",
    "    manera:\n",
    "    *   ds_Source_IPL_csv\n",
    "    *   ds_Destination_IPL_json    \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/5yHQGjhR/adf284.png\"></center>\n",
    "\n",
    "19. Crearemos un nuevo pipeline, con nuevos ajustes que nos permita mayor eficiencia al momento de\n",
    "    lanzar nuestro proceso. Nuestro pipeline llevará el nombre de **pl_Copy_Full_IPL_DATA** y al cual\n",
    "    le agregamos una actividad **Lookup**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/Hk18ZYB6/adf285.png\"></center>\n",
    "\n",
    "20. Eliminaremos los archivos que se almacenaron en el contenedor **raw** de nuestro ADLS y cargaremos \n",
    "    el archivo **Files.txt**, que es basicamente un archivo que almacena los nombres de todos los archivos\n",
    "    que queremos extraer desde el sitio de Github\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/jjd1fb0j/adf286.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/KzCpC3KK/adf287.png\"></center>\n",
    "\n",
    "21. Crearemos un nuevo dataset que haga referencia hacia el archivo **Files.txt** que recien subimos a nuestro \n",
    "    ADLS, al contenedor **raw**. Este dataset llevará el nombre de **ds_listOfFiles**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/TYVNHwTw/adf288.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/hPc1v0qD/adf289.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/MphcMWj7/adf290.png\"></center>\n",
    "\n",
    "22. Realizamos ajustes a nuestra actividad **Lookup** de nuestro pipeline **pl_Copy_Full_IPL_DATA**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/XvSJNQTx/adf291.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/VkMfhXdt/adf292.png\"></center>\n",
    "\n",
    "23. Vamos a **Validar** y luego ejecutar el pipeline utilizando **Debug**. Revisaremos que nos devuelve\n",
    "    el **Output**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/hPRcdfCP/adf293.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/bw3hWLqs/adf294.png\"></center>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 7 - Agregar la actividad \"ForEach\"\n",
    "\n",
    "24. Agregaremos una actividad **ForEach** a nuestro Pipeline y le realizaremos los ajustes necesarios\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/1t4pyBgW/adf295.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/Qt0KKT7F/adf296.png\"></center>\n",
    "\n",
    "Utilizaremos el contenido dinámico **@activity('Lookup All File Names').output.value** en la configuración\n",
    "de la actividad ForEach, esto quiere decir, que de la actividad previa **Lookup All File Name** extraera\n",
    "solo **value**. Corresponde al array que contiene los nombres de los archivos que utilizaremos.\n",
    "\n",
    "Esto es el **Output** de la actividad previa **Lookup**\n",
    "```\n",
    "{\n",
    "    \"count\":15,\n",
    "    \"value\": [\n",
    "        {\n",
    "            \"Files\":\"ipl 2008.csv\"\n",
    "        }\n",
    "        {\n",
    "            \"Files\":\"ipl 2009.csv\"            \n",
    "        }\n",
    "        ...\n",
    "        ...\n",
    "    ]\n",
    "\n",
    "}\n",
    "```\n",
    "<center><img src=\"https://i.postimg.cc/dtzkCvhj/adf297.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/8CG7yHBF/adf298.png\"></center>\n",
    "\n",
    "25. Ahora, editaremos la tarea que realizará nuestro **ForEach**. Agregamos la actividad **Copy Data**.\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/CKymKWCR/adf299.png\"></center>\n",
    "\n",
    "Para la configuración del origen **Source** se creará el contenido dinámico **@items().Files** que captura \n",
    "los valores de **Files**. Esto es el **Output** de la actividad previa **Lookup**\n",
    "```\n",
    "{\n",
    "    \"count\":15,\n",
    "    \"value\": [\n",
    "        {\n",
    "            \"Files\":\"ipl 2008.csv\"\n",
    "        }\n",
    "        {\n",
    "            \"Files\":\"ipl 2009.csv\"            \n",
    "        }\n",
    "        ...\n",
    "        ...\n",
    "    ]\n",
    "\n",
    "}\n",
    "```\n",
    "\n",
    "Por cada valor de **File** que se tenga, se irá heredando al parámetro del dataset de origen **dataset().SourceFileName**,\n",
    "por tanto, se irá heredando cada valor de **File** como nombres de archivos para el dataset de origen\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/NfSxNWzd/adf300.png\"></center>\n",
    "\n",
    "Para la configuración del destino **Sink** se creará el contenido dinámico **@replace(@items().Files,'.csv','.json')**\n",
    "que tendrá la misma función que el contenido dinámico para el Origen, solo que en este caso se reemplazará su extensión\n",
    "por una JSON.\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/QdkwRQW9/adf301.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/FFM6zWyk/adf302.png\"></center>\n",
    "\n",
    "26. Vamos a **Validar** y luego ejecutar el pipeline utilizando **Debug**.\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/4x7nP3KS/adf303.png\"></center>\n",
    "\n",
    "27. Si revisamos nuestro ADLS, el contenedor **raw** se veria de la siguiente manera\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/nL9RnqXG/adf304.png\"></center>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
