{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Paso 2.4 - Creación de Pipeline \"pl_Copy_Full_IPL_Data_using_DF\"**\n",
    "\n",
    "1. Cargar todos los archivos JSON del contenedor \"raw\" de nuestro ADLS utilizando Data Flows. Para ello creamos un nuevo Pipeline llamado **pl_Copy_Full_IPL_Data_using_DF** en el cual ejecutaremos nuestro Data Flow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargar todos los archivos JSON del contenedor \"raw\" de nuestro ADLS utilizando Data Flows\n",
    "\n",
    "Para ello previamente vamos a truncar la tabla **dbo.tbl_IPLData**:\n",
    "\n",
    "    TRUNCATE TABLE [dbo].[tbl_IPLData]\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/VL3dndQ7/adf328.png\"></center>\n",
    "\n",
    "Crearemos un Data Flow llamado **df_Copy_IPL_Data**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/Hn83vVSS/adf329.png\"></center>\n",
    "\n",
    "En el dataset de origen **ds_Valid_IPL_Data_Json** dejaremos vacio el recuadro del archivo, dado que utilizaremos\n",
    "un comodin para llamar a todos los archivos JSON\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/c4wGrHsM/adf330.png\"></center>    \n",
    "\n",
    "En la opción **Column to store file name** debemos colocar **SourceFileName**. De esta manera, estaremos agregando\n",
    "una nueva columna con el nombre del archivo al cual cada registro pertenece\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/rwTXWks6/adf331.png\"></center>\n",
    "\n",
    "Vemos que todos los tipos de datos para un archivo JSON son del tipo **String**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/W17RwHqd/adf332.png\"></center>    \n",
    "\n",
    "Podemos visualizar en el **Data Preview** que vamos a tener columnas con valores NULL, por tanto, tenemos que\n",
    "modificar el tipo de datos para aquellas columnas\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/KYc6qDtJ/adf333.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/85jqDkKv/adf334.png\"></center> \n",
    "\n",
    "Desde la pestaña **Projection** utilizamos la opción **Overwrite schema** para modificar los tipos de datos iniciales\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/k4zL5rzp/adf335.png\"></center>\n",
    "\n",
    "Crearemos una tarea **sink** que haga referencia hacia Azure SQL DB, a nuestro dataset de destino **ds_AzureSqlTable_IPL_Data**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/DfQtTN5B/adf336.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/N0rzPC58/adf337.png\"></center>    \n",
    "<center><img src=\"https://i.postimg.cc/NFQCFgbb/adf338.png\"></center>\n",
    "\n",
    "Debemos mapear las columnas obtenidas del **Source** con las columnas de la tabla \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/vHq28wnL/adf339.png\"></center>  \n",
    "<center><img src=\"https://i.postimg.cc/05ZcZ1VR/adf341.png\"></center>\n",
    "\n",
    "Creamos un nuevo Pipeline llamado **pl_Copy_Full_IPL_Data_using_DF** en el cual ejecutaremos nuestro Data Flow. Vamos a **Validar** y luego ejecutar el pipeline utilizando **Debug**.\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/52zBhhSt/adf343.png\"></center>   \n",
    "\n",
    "Podemos ver que en total se cargaron 898 registros y la columna **Date** de la tabla solo tiene valores NULL.\n",
    "Debemos corregir este error que tenemos con la columna **Date**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/YSf19QVK/adf344.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/XND9pj2J/adf345.png\"></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corrección problema columna \"Date\"\n",
    "\n",
    "Vamos a corregir el problema de tipo de dato que tenemos con la columna **Date**. Agregamos una actividad **Derived Column** intermedia para generar una nueva columna llamada **NewDate** que tendrá los datos de la columna **Date** formateados\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/KvRwMYxs/adf346.png\"></center>\n",
    "\n",
    "Vamos a utilizar la expresión: **coalesce(toDate(Date,'dd-MM-yyyy'))**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/T2rqHMQY/adf347.png\"></center>\n",
    "\n",
    "En la tarea **sink** debemos mapear la nueva columna **NewDate** que acabamos de crear con la columna **Date** de la tabla\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/pLyjvgQj/adf348.png\"></center>\n",
    "\n",
    "Previo a ejecutar nuestro Pipeline, truncaremos la tabla **dbo.tbl_IPLData**:\n",
    "\n",
    "    TRUNCATE TABLE [dbo].[tbl_IPLData] \n",
    "\n",
    "Vamos a **Validar** y luego ejecutar el pipeline utilizando **Debug**.\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/5tL6N1XX/adf349.png\"></center>\n",
    "\n",
    "Ahora podemos ver que nuestra columna se visualiza de manera correcta\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/QtDVFP70/adf350.png\"></center>\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
