{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proyecto 1B - Mapping Data Flow para carga de archivos JSON desde ADLS hacia Azure SQL DB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 8 - Creación de un Linked Service que haga referencia a Azure SQL DB\n",
    "\n",
    "28. Creación y configuración del Linked Service que hace referencia hacia Azure SQL DB\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/Yqpjr13w/adf305.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/85RPD5f5/adf306.png\"></center>\n",
    "\n",
    "Indicamos el **Server name**, la **base de datos**, el **user name** y la **password**.\n",
    "Nos conectaremos sin utilizar la seguridad por medio de secretos que nos brinda Azure Key Vault\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/qMbBpWq8/adf307.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/g0RGqJDD/adf308.png\"></center>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 9 - Creación de los datasets\n",
    "\n",
    "29. Creación y configuración de los dataset de origen y destino\n",
    "\n",
    "    El dataset de origen será **ds_Valid_IPL_Data_Json**. Este archivo tendrá como referencia a un único archivo, \n",
    "    al archivo **ipl 2008.json**. Estamos referenciando a un solo archivo por motivos de prueba, si vemos que se\n",
    "    carga sin problemas, mas adelante cargaremos todos los archivos JSON del contenedor **raw**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/pL0tfjzz/adf309.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/TwbMvHSJ/adf310.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/WzPRNwcL/adf311.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/5y5h6QfH/adf312.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/Ghd06Kjv/adf313.png\"></center>\n",
    "\n",
    "El dataset de destino será **ds_AzureSqlTable_IPL_Data**. Este dataset hace referencia a la tabla **dbo.tbl_IPLData**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/RFSfjjqj/adf314.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/QCV7M1Qm/adf315.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/nzhjdBPx/adf316.png\"></center>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 10 - Creación de un nuevo Pipeline\n",
    "\n",
    "30. Creación y configuración de un nuevo Pipeline que se llamará **pl_Copy_Valid_IPL_To_SQL** que nos permitirá \n",
    "    realizar la carga del archivo **ipl 2008.json** en la tabla **dbo.tbl_IPLData**\n",
    "\n",
    "    Agregaremos la actividad **Copy Data**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/MTt9f7hj/adf317.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/j2FvZsqx/adf318.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/pXmsynkp/adf319.png\"></center>    \n",
    "<center><img src=\"https://i.postimg.cc/xd25spQz/adf320.png\"></center>\n",
    "\n",
    "Esta es la estructura de la tabla **dbo.tbl_IPLData**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/G29yzv4D/adf321.png\"></center>\n",
    "\n",
    "Esta es la estructura que tiene el archivo **ipl 2008.csv**, pero lo vemos como ejemplo, para ver los nombres de\n",
    "las columnas\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/5t2pz7Mq/adf322.png\"></center>\n",
    "\n",
    "Realizamos el mapeo de las columnas del archivo **ipl 2008.json** frente a las columnas de la tabla **dbo.tbl_IPLData**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/gcZs3L15/adf323.png\"></center>\n",
    "\n",
    "Eliminamos la columna **Date**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/bN0RBcy9/adf324.png\"></center>\n",
    "\n",
    "31. Vamos a **Validar** y luego ejecutar el pipeline utilizando **Debug**.\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/Vs0wM4f8/adf326.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/VvQVXqgf/adf327.png\"></center>\n",
    "\n",
    "Podemos ver que en total se cargaron 59 registros y la columna **Date** de la tabla solo tiene valores NULL\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/MH71NVSp/adf325.png\"></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 11 - Cargar todos los archivos JSON del contenedor \"raw\" de nuestro ADLS utilizando Data Flows\n",
    "\n",
    "32. Para ello previamente vamos a truncar la tabla **dbo.tbl_IPLData**:\n",
    "\n",
    "    TRUNCATE TABLE [dbo].[tbl_IPLData]\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/VL3dndQ7/adf328.png\"></center>\n",
    "\n",
    "33. Crearemos un Data Flow llamado **df_Copy_IPL_Data**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/Hn83vVSS/adf329.png\"></center>\n",
    "\n",
    "En el dataset de origen **ds_Valid_IPL_Data_Json** dejaremos vacio el recuadro del archivo, dado que utilizaremos\n",
    "un comodin para llamar a todos los archivos JSON\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/c4wGrHsM/adf330.png\"></center>    \n",
    "\n",
    "En la opción **Column to store file name** debemos colocar **SourceFileName**. De esta manera, estaremos agregando\n",
    "una nueva columna con el nombre del archivo al cual cada registro pertenece\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/rwTXWks6/adf331.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/W17RwHqd/adf332.png\"></center>    \n",
    "\n",
    "Podemos visualizar en el **Data Preview** que vamos a tener columnas con valores NULL, por tanto, tenemos que\n",
    "modificar el tipo de datos para aquellas columnas\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/KYc6qDtJ/adf333.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/85jqDkKv/adf334.png\"></center>    \n",
    "<center><img src=\"https://i.postimg.cc/k4zL5rzp/adf335.png\"></center>\n",
    "\n",
    "Crearemos una tarea **sink** que haga referencia hacia Azure SQL DB, a nuestro dataset de destino **ds_AzureSqlTable_IPL_Data**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/DfQtTN5B/adf336.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/N0rzPC58/adf337.png\"></center>    \n",
    "<center><img src=\"https://i.postimg.cc/NFQCFgbb/adf338.png\"></center>\n",
    "\n",
    "Debemos mapear las columnas obtenidas del **Source** con las columnas de la tabla \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/vHq28wnL/adf339.png\"></center>  \n",
    "<center><img src=\"https://i.postimg.cc/05ZcZ1VR/adf341.png\"></center>\n",
    "\n",
    "34. Creamos un nuevo Pipeline llamado **pl_Copy_Full_IPL_Data_using_DF** en el cual ejecutaremos nuestro Data Flow. Vamos a \n",
    "    **Validar** y luego ejecutar el pipeline utilizando **Debug**.\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/52zBhhSt/adf343.png\"></center>   \n",
    "\n",
    "Podemos ver que en total se cargaron 898 registros y la columna **Date** de la tabla solo tiene valores NULL.\n",
    "Debemos corregir este error que tenemos con la columna **Date**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/YSf19QVK/adf344.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/XND9pj2J/adf345.png\"></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 12 - Corrección problema columna \"Date\"\n",
    "\n",
    "32. Vamos a corregir el problema de tipo de dato que tenemos con la columna **Date**\n",
    "\n",
    "    Agregamos una actividad **Derived Column** intermedia para generar una nueva columna llamada **NewDate** que tendrá \n",
    "    los datos de la columna **Date** formateados\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/KvRwMYxs/adf346.png\"></center>\n",
    "\n",
    "Vamos a utilizar la expresión: **coalesce(toDate(Date,'dd-MM-yyyy'))**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/T2rqHMQY/adf347.png\"></center>\n",
    "\n",
    "En la tarea **sink** debemos mapear la nueva columna **NewDate** que acabamos de crear con la columna **Date** de la tabla\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/pLyjvgQj/adf348.png\"></center>\n",
    "\n",
    "33. Previo a ejecutar nuestro Pipeline, truncaremos la tabla **dbo.tbl_IPLData**:\n",
    "\n",
    "    TRUNCATE TABLE [dbo].[tbl_IPLData] \n",
    "\n",
    "34. Vamos a **Validar** y luego ejecutar el pipeline utilizando **Debug**.\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/5tL6N1XX/adf349.png\"></center>\n",
    "\n",
    "35. Ahora podemos ver que nuestra columna se visualiza de manera correcta\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/QtDVFP70/adf350.png\"></center>\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
