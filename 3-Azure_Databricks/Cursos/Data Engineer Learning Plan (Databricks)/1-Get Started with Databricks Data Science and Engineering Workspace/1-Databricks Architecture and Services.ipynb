{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.1 - Databricks Architecture and Services**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Echemos un vistazo a la arquitectura de la plataforma Databricks. Aunque entender los detalles de todos los componentes y cómo se integran es responsabilidad de un administrador de la plataforma, como ingeniero de datos es bueno tener un amplio conocimiento de la estructura y de cómo todo encaja."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este diagrama ilustra la arquitectura de Databricks. El plano de control consiste en los servicios backend que Databricks gestiona en su propia cuenta en la nube, alineada con el servicio en la nube que utiliza el cliente (AWS, Azure o GCP). Aunque la mayoría de sus datos no viven aquí, algunos elementos como los comandos del notebook y las configuraciones del workspace se almacenan en el plano de control y se cifran en reposo (rest). A través del plano de control y de la interfaz de usuario y las API asociadas que proporciona, se pueden: lanzar clústeres, iniciar jobs y obtener resultados e interactuar con los metadatos de las tablas. El plano de datos es donde se procesan todos los datos. Siguiendo el modelo clásico de plano de datos, todos los recursos de computación del plano de datos residen en su propia cuenta de nube. El plano de datos publica recursos informáticos, también conocidos como clústeres, se conecta a los almacenes de datos que respaldan DBFS y, opcionalmente, proporciona conexiones a fuentes de datos externas, ya sea dentro de la misma cuenta de nube del cliente o en otro lugar de Internet, por ejemplo, fuentes de datos de GCP y SQL, o data lake almacenados en S3, Azure Blob storage o GCS."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i.postimg.cc/5NBsp9r7/db271.png\"></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La aplicación web de Databricks ofrece tres servicios diferentes que satisfacen las necesidades específicas de varias personas: Databricks SQL, Databricks Machine Learning y Data Science and Engineering Workspace, también conocido como el workspace. Utilizaremos la vista Data Science and Engineering para las primeras 3/4 partes del curso y Databricks SQL para un módulo posterior. Cargaremos el material incrementalmente como un repo que es una colección de \"hosted notebooks\". Cubriremos la pestaña Jobs más adelante en el curso cuando veamos Orchestration, que tiene dos componentes, Delta Live tables y Jobs. Por último, hablaremos más sobre clusters en las próximas tres diapositivas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i.postimg.cc/bJYGXgYS/db272.png\"></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Databricks Cluster es un conjunto de recursos de computación y configuraciones en las que se ejecutan cargas de trabajo de ingeniería de datos, ciencia de datos y análisis de datos. Estas cargas de trabajo se ejecutan como un conjunto de comandos en un notebook o como un job. Entre las aplicaciones típicas se incluyen los pipelines ETL de producción, la analítica de streaming, la analítica ad-hoc y el machine learning. Los clústeres viven en el plano de datos dentro de la cuenta de nube de su organización, aunque la gestión de clústeres es una función del plano de control que forma parte de los servicios ofrecidos por la plataforma Databricks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i.postimg.cc/8Cv8pg5q/db273.png\"></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los propios clústeres consisten en un conjunto de una o más instancias de máquinas virtuales sobre las que Apache Spark distribuye las cargas de trabajo computacionales. En un caso típico, un clúster tiene un nodo driver junto con uno o más nodos worker, aunque Databricks también proporciona un modelo de nodo único (single node), que normalmente se limita al desarrollo o al testing con cargas de trabajo pequeñas. El driver distribuye las cargas de trabajo entre los nodos worker disponibles."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i.postimg.cc/CL8bsvRw/db274.png\"></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Databricks distingue entre clusters multipropósito (all-purpose) y job clusters. Los All-purpose clusters analizan datos de forma colaborativa mediante notebooks interactivos. Puede crear un all-purpose cluster utilizando el workspace o programáticamente utilizando la interfaz de línea de comandos o REST API. Puede finalizar y reiniciar manualmente un \"all-purpose cluster\" y varios usuarios pueden compartir \"all-purpose clusters\" para realizar análisis interactivos en colaboración. Los \"job clusters\" ejecutan trabajos automatizados de forma ágil y robusta. Databricks Job Scheduler crea un job cluster cuando se ejecuta un job en un nuevo job cluster y termina el cluster cuando el job se ha completado. No se puede reiniciar un job cluster. Estas propiedades garantizan un entorno de ejecución aislado para todos y cada uno de los jobs. En el caso de los Job clusters, la información de configuración se conserva durante un máximo de 30 clusters recientemente finalizados por el job scheduler. La información de configuración de los Purpose clusters se conserva para un máximo de 70 clústeres finalizados en los últimos 30 días. Para retener información más allá de esto, un administrador debe fijar el cluster.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i.postimg.cc/t4HWSh6W/db275.png\"></center>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
