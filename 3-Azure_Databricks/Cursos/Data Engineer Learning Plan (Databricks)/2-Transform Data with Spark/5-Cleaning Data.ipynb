{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"1458f145-2367-4f70-b459-36bbc68925e7","showTitle":false,"title":""}},"source":["<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n","  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n","</div>"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"9f41f8ad-0382-4397-bf90-63253665cb33","showTitle":false,"title":""}},"source":["### **Limpieza de datos**\n","\n","A medida que inspeccionamos y limpiamos nuestros datos, necesitaremos construir varias expresiones de columna y consultas para expresar las transformaciones que aplicaremos a nuestro conjunto de datos.\n","\n","Las expresiones de columna se construyen a partir de columnas existentes, operadores y funciones integradas. Pueden utilizarse en sentencias **`SELECT`** para expresar transformaciones que crean nuevas columnas.\n","\n","Muchos comandos de consulta SQL estándar (por ejemplo, **`DISTINCT`**, **`WHERE`**, **`GROUP BY`**, etc.) están disponibles en Spark SQL para expresar transformaciones.\n","\n","En este notebook, revisaremos algunos conceptos que pueden diferir de otros sistemas a los que estés acostumbrado, así como algunas funciones útiles para operaciones comunes.\n","\n","Prestaremos especial atención a los comportamientos en torno a los valores **`NULL`**, así como al formateo de strings y campos datetime.\n","\n","#### **Objetivos de aprendizaje**\n","Al final de esta lección, deberás ser capaz de:\n","- Resumir datasets y describir comportamientos null\n","- Recuperar y eliminar duplicados\n","- Validar datasets para recuentos esperados, valores perdidos y registros duplicados\n","- Aplicar transformaciones comunes para limpiar y transformar datos"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"d18793af-0725-471a-bff2-c7776d87a116","showTitle":false,"title":""}},"source":["#### **Run Setup**\n","\n","El setup script creará los datos y declarará los valores necesarios para que el resto de este notebook se ejecute."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"7c3b51f8-de89-4ce1-9ff1-60668a2428b8","showTitle":false,"title":""}},"outputs":[],"source":["%run ../Includes/Classroom-Setup-02.4"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"e2e4306c-dc66-4b79-8dcf-e643d750d4c4","showTitle":false,"title":""}},"source":["#### **Resumen de datos**\n","\n","Trabajaremos con registros de nuevos usuarios de la tabla **`users_dirty`**, que tiene el siguiente esquema:\n","\n","| field | type | description |\n","|---|---|---|\n","| user_id | string | unique identifier |\n","| user_first_touch_timestamp | long | time at which the user record was created in microseconds since epoch |\n","| email | string | most recent email address provided by the user to complete an action |\n","| updated | timestamp | time at which this record was last updated |\n","\n","Empecemos por contar los valores de cada campo de nuestros datos."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"2a50e73b-6852-476f-aacc-93e110835ef7","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","SELECT count(*), count(user_id), count(user_first_touch_timestamp), count(email), count(updated)\n","FROM users_dirty"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/XYs1S6ws/db357.png\"></center>"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"b68afee9-7d83-4f2d-baff-8181b931a0f3","showTitle":false,"title":""}},"source":["#### **Inspeccionar los datos que faltan**\n","\n","Basándonos en los recuentos anteriores, parece que hay al menos un puñado de valores nulos en todos nuestros campos.\n","\n","**NOTA:** Los valores nulos se comportan incorrectamente en algunas funciones matemáticas, incluyendo **`count()`**.\n","\n","- **`count(col)`** omite valores **`NULL`** al contar columnas o expresiones específicas.\n","- **`count(*)`** es un caso especial que cuenta el número total de filas (incluyendo filas que son sólo valores **`NULL`**).\n","\n","Podemos contar los valores nulos de un campo filtrando los registros en los que ese campo es nulo, utilizando:  \n","**`count_if(col IS NULL)`** o **`count(*)`** con un filtro para donde **`col IS NULL`**. \n","\n","Ambas sentencias cuentan correctamente los registros en los que faltan correos electrónicos."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"ca9ee04e-da53-4f78-bf17-0c58df642a70","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","SELECT count_if(email IS NULL) FROM users_dirty;\n","SELECT count(*) FROM users_dirty WHERE email IS NULL;"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/5tj7fKgb/db358.png\"></center>"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"49a79bff-7ede-447b-b5a0-835c167bcda5","showTitle":false,"title":""}},"outputs":[],"source":["%python \n","from pyspark.sql.functions import col\n","usersDF = spark.read.table(\"users_dirty\")\n","\n","usersDF.selectExpr(\"count_if(email IS NULL)\")\n","usersDF.where(col(\"email\").isNull()).count()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/DzDC0Qps/db359.png\"></center>"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"a0515b5a-3eec-4985-b304-cad5e1bed1ed","showTitle":false,"title":""}},"source":["#### **Deduplicar filas**\n","Podemos utilizar **`DISTINCT *`** para eliminar registros realmente duplicados en los que filas enteras contienen los mismos valores."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"6bbfbb71-3ac7-4bde-9593-68e5cfae34ee","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","SELECT DISTINCT(*) FROM users_dirty"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/650Ynx1B/db360.png\"></center>"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"619335aa-a3ce-4195-a1e8-67b017d3341b","showTitle":false,"title":""}},"outputs":[],"source":["%python\n","usersDF.distinct().count()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/fL98931P/db361.png\"></center>"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"bb1ca6f7-0901-45dc-a5b7-4157fb573648","showTitle":false,"title":""}},"source":["#### **Deduplicar filas basándose en columnas específicas**\n","\n","El siguiente código utiliza **`GROUP BY`** para eliminar registros duplicados basándose en los valores de las columnas **`user_id`** y **`user_first_touch_timestamp`**. (Recordemos que estos dos campos se generan cuando se encuentra por primera vez un usuario determinado, formando así tuplas únicas).\n","\n","Aquí, estamos utilizando la función agregada **`max`** como un hack to:\n","- Mantener los valores de las columnas **`email`** y **`updated`** en el resultado de nuestro group by\n","- Capturar los correos electrónicos no nulos cuando hay varios registros presentes"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"40f0eeed-5d71-41ae-9a68-c0f26dc0ec99","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","CREATE OR REPLACE TEMP VIEW deduped_users AS \n","SELECT user_id, user_first_touch_timestamp, max(email) AS email, max(updated) AS updated\n","FROM users_dirty\n","WHERE user_id IS NOT NULL\n","GROUP BY user_id, user_first_touch_timestamp;\n","\n","SELECT count(*) FROM deduped_users"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/5yWnq4V2/db362.png\"></center>"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"7adc4128-e751-43c5-ba0c-e3b0e49ac739","showTitle":false,"title":""}},"outputs":[],"source":["%python\n","from pyspark.sql.functions import max\n","dedupedDF = (usersDF\n","    .where(col(\"user_id\").isNotNull())\n","    .groupBy(\"user_id\", \"user_first_touch_timestamp\")\n","    .agg(max(\"email\").alias(\"email\"), \n","         max(\"updated\").alias(\"updated\"))\n","    )\n","\n","dedupedDF.count()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/CMbvMqGB/db363.png\"></center>"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"e26b59c9-ecaa-410e-93c7-15f3e882c7b5","showTitle":false,"title":""}},"source":["Vamos a confirmar que tenemos el recuento esperado de registros restantes después de la deduplicación basada en valores distintos **`user_id`** y **`user_first_touch_timestamp`**."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"7df601ac-035d-416f-901e-5710f32187f6","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","SELECT COUNT(DISTINCT(user_id, user_first_touch_timestamp))\n","FROM users_dirty\n","WHERE user_id IS NOT NULL"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/28m01SGH/db364.png\"></center>"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"3b48e17f-da90-4505-8e53-64a1c771f2f9","showTitle":false,"title":""}},"outputs":[],"source":["%python\n","(usersDF\n","    .dropDuplicates([\"user_id\", \"user_first_touch_timestamp\"])\n","    .filter(col(\"user_id\").isNotNull())\n","    .count())"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/fy758Gzj/db365.png\"></center>"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"a4819844-b666-4c67-8c4f-45e5f112a2b8","showTitle":false,"title":""}},"source":["#### **Validar Datasets**\n","Basándonos en nuestra revisión manual anterior, hemos confirmado visualmente que nuestros recuentos son los esperados.\n"," \n","También podemos realizar la validación mediante programación utilizando filtros sencillos y cláusulas **`WHERE`**.\n","\n","Comprueba que el **`user_id`** de cada fila es único."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"2b1a1a1b-2a44-4354-bb37-4675aea05e68","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","SELECT max(row_count) <= 1 no_duplicate_ids \n","FROM (\n","      SELECT user_id, count(*) AS row_count\n","      FROM deduped_users\n","      GROUP BY user_id\n","      )"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/qvvQGD9y/db366.png\"></center>"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"7612dc09-59ee-4bb5-a0db-77854df58aa3","showTitle":false,"title":""}},"outputs":[],"source":["%python\n","from pyspark.sql.functions import count\n","\n","display(dedupedDF\n","    .groupBy(\"user_id\")\n","    .agg(count(\"*\").alias(\"row_count\"))\n","    .select((max(\"row_count\") <= 1).alias(\"no_duplicate_ids\")))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/XY1L1cbh/db367.png\"></center>"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"213c1a1d-4663-4fdf-b896-c7a5e8e55552","showTitle":false,"title":""}},"source":["Confirm that each email is associated with at most one **`user_id`**."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"74f37a8e-aedf-409c-827b-e5ca698ac73b","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","SELECT max(user_id_count) <= 1 at_most_one_id FROM (\n","  SELECT email, count(user_id) AS user_id_count\n","  FROM deduped_users\n","  WHERE email IS NOT NULL\n","  GROUP BY email)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/Zq9cGBYq/db368.png\"></center>"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"07f56c87-1eef-4777-91f2-928bccf6a993","showTitle":false,"title":""}},"outputs":[],"source":["%python\n","\n","display(dedupedDF\n","    .where(col(\"email\").isNotNull())\n","    .groupby(\"email\")\n","    .agg(count(\"user_id\").alias(\"user_id_count\"))\n","    .select((max(\"user_id_count\") <= 1).alias(\"at_most_one_id\")))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/FK2ZNr1V/db369.png\"></center>"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"fd3581c4-9f7d-41dd-a788-444c2264ac40","showTitle":false,"title":""}},"source":["#### **Formato de fecha y Regex**\n","Ahora que hemos eliminado los campos nulos y los duplicados, podemos extraer más valor de los datos.\n","\n","El código siguiente:\n","- Escala correctamente y castea **`user_first_touch_timestamp`** en un timestamp válido.\n","- Extrae la fecha del calendario y la hora de este timestamp en un formato legible.\n","- Utiliza **`regexp_extract`** para extraer los dominios de la columna email utilizando regex"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"8a9a72ab-7f36-4856-9dad-247224c7053f","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","SELECT *, \n","  date_format(first_touch, \"MMM d, yyyy\") AS first_touch_date,\n","  date_format(first_touch, \"HH:mm:ss\") AS first_touch_time,\n","  regexp_extract(email, \"(?<=@).+\", 0) AS email_domain\n","FROM (\n","  SELECT *,\n","    CAST(user_first_touch_timestamp / 1e6 AS timestamp) AS first_touch \n","  FROM deduped_users\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/Bb3BPmT8/db370.png\"></center>"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/SRG76cdg/db371.png\"></center>"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"8626b67f-10fa-4c38-9e85-8b855560182e","showTitle":false,"title":""}},"outputs":[],"source":["%python\n","from pyspark.sql.functions import date_format, regexp_extract\n","\n","display(dedupedDF\n","    .withColumn(\"first_touch\", (col(\"user_first_touch_timestamp\") / 1e6).cast(\"timestamp\"))\n","    .withColumn(\"first_touch_date\", date_format(\"first_touch\", \"MMM d, yyyy\"))\n","    .withColumn(\"first_touch_time\", date_format(\"first_touch\", \"HH:mm:ss\"))\n","    .withColumn(\"email_domain\", regexp_extract(\"email\", \"(?<=@).+\", 0))\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/Y2N3Bw7Q/db372.png\"></center>"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"5ab8f821-c94f-437e-ac47-ca23f95a1191","showTitle":false,"title":""}},"outputs":[],"source":["%python\n","from pyspark.sql.functions import date_format, regexp_extract\n","\n","display(dedupedDF\n","    .withColumn(\"first_touch\", (col(\"user_first_touch_timestamp\") / 1e6).cast(\"timestamp\"))\n","    .withColumn(\"first_touch_date\", date_format(\"first_touch\", \"MMM d, yyyy\"))\n","    .withColumn(\"first_touch_time\", date_format(\"first_touch\", \"HH:mm:ss\"))\n","    .withColumn(\"email_domain\", regexp_extract(\"email\", \"(?<=@).+\", 0))\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/VLYFYHsp/db373.png\"></center>"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"3e6c6fe8-d168-4aa6-9078-1af9fb3aa451","showTitle":false,"title":""}},"source":["Ejecute la siguiente celda para eliminar las tablas y archivos asociados a esta lección."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"98c129f2-62ee-443a-8508-cc27aec2cae6","showTitle":false,"title":""}},"outputs":[],"source":["%python\n","DA.cleanup()"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"c3344b94-e38e-4b19-bd8f-800d627449c2","showTitle":false,"title":""}},"source":["-sandbox\n","&copy; 2022 Databricks, Inc. All rights reserved.<br/>\n","Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n","<br/>\n","<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":2},"notebookName":"DE 2.4 - Cleaning Data","widgets":{}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
