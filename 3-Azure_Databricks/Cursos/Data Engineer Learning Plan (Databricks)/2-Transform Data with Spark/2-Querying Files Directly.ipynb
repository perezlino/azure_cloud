{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"b41c6356-417e-4a42-abd9-34bbd734f080","showTitle":false,"title":""}},"source":["<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n","  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n","</div>"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"f372d5a6-7395-4468-b696-6cc318e34a0e","showTitle":false,"title":""}},"source":["### **Extracción de datos directamente de archivos con Spark SQL**\n","\n","En este notebook, aprenderás a extraer datos directamente de archivos usando Spark SQL en Databricks.\n","\n","Varios formatos de archivo soportan esta opción, pero es más útil para formatos de datos autodescriptivos (como Parquet y JSON).\n","\n","#### **Objetivos de aprendizaje**\n","Al final de esta lección, deberías ser capaz de:\n","- Utilizar Spark SQL para consultar directamente archivos de datos\n","- Layer views y CTEs para facilitar la consulta de archivos de datos\n","- Aprovechar los métodos **`text`** y **`binaryFile`** para revisar el contenido de archivos sin procesar"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"69691d12-a7d9-4d2d-a396-948be8723253","showTitle":false,"title":""}},"source":["#### **Run Setup**\n","\n","El setup script creará los datos y declarará los valores necesarios para que el resto de este notebook se ejecute."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"537f151e-1a2d-4244-9d97-14a25b3fc01f","showTitle":false,"title":""}},"outputs":[],"source":["%run ../Includes/Classroom-Setup-02.1"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"35bc9be6-7d08-4d4f-b8f5-af8282aa1dd8","showTitle":false,"title":""}},"source":["#### **Data Overview**\n","\n","En este ejemplo, trabajaremos con una muestra de datos Kafka sin procesar (raw Kafka data) escritos como archivos JSON. \n","\n","Cada archivo contiene todos los registros consumidos durante un intervalo de 5 segundos, almacenados con el schema completo de Kafka como un archivo JSON de múltiples registros (multiple-record JSON file).\n","\n","| field | type | description |\n","| --- | --- | --- |\n","| key | BINARY | The **`user_id`** field is used as the key; this is a unique alphanumeric field that corresponds to session/cookie information |\n","| value | BINARY | This is the full data payload (to be discussed later), sent as JSON |\n","| topic | STRING | While the Kafka service hosts multiple topics, only those records from the **`clickstream`** topic are included here |\n","| partition | INTEGER | Our current Kafka implementation uses only 2 partitions (0 and 1) |\n","| offset | LONG | This is a unique value, monotonically increasing for each partition |\n","| timestamp | LONG | This timestamp is recorded as milliseconds since epoch, and represents the time at which the producer appends a record to a partition |"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"4fbde235-84ae-4d86-a07a-9dc2656414f9","showTitle":false,"title":""}},"source":["Note that our source directory contains many JSON files."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"a5c77efe-251e-494d-8df8-c186469df828","showTitle":false,"title":""}},"outputs":[],"source":["%python\n","print(DA.paths.kafka_events)\n","\n","files = dbutils.fs.ls(DA.paths.kafka_events)\n","display(files)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/15ScMR8L/db337.png\"></center>"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"011adde3-2325-41ed-9654-44c17ef59734","showTitle":false,"title":""}},"source":["En este caso, utilizaremos rutas de archivo relativas a los datos que se han escrito en el DBFS root. \n","\n","La mayoría de workflows requerirán que los usuarios accedan a datos desde ubicaciones externas de almacenamiento en la nube. \n","\n","En la mayoría de las empresas, un administrador del workspace será responsable de configurar el acceso a estas ubicaciones de almacenamiento.\n","\n","Las instrucciones para configurar y acceder a estas ubicaciones se pueden encontrar en los cursos autodidácticos específicos para proveedores de nube titulados \" \"Cloud Architecture & Systems Integrations\" (Arquitectura de nube e integraciones de sistemas)."]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"e1e96934-406a-4e42-8336-f7c938ad980e","showTitle":false,"title":""}},"source":["#### **Consultar un único archivo**\n","\n","Para consultar los datos contenidos en un único archivo, ejecute la consulta con el siguiente patrón:\n","\n","<strong><code>SELECT * FROM file_format.&#x60;/path/to/file&#x60;</code></strong>\n","\n","Preste especial atención al uso de comillas (no simples) alrededor de la ruta."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"2bc188dc-1fc4-434d-a853-9ee036ff9244","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","SELECT * FROM json.`${DA.paths.kafka_events}/001.json`"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"509aed4f-e125-4b6b-b39c-aa2d23f7ab34","showTitle":false,"title":""}},"source":["Observe que nuestra vista previa muestra las 321 filas de nuestro archivo fuente."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/k4dB9GPC/db338.png\"></center>"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"a30c342d-8c18-45d5-aeb4-83b015ab1818","showTitle":false,"title":""}},"source":["#### **Consultar un directorio de archivos**\n","\n","Suponiendo que todos los archivos de un directorio tengan el mismo formato y schema, todos los archivos pueden consultarse simultáneamente especificando la ruta del directorio en lugar de un archivo individual."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"f164e0f8-edac-4284-bdc0-38c6c073a142","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","SELECT * FROM json.`${DA.paths.kafka_events}`"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"2e74e71d-f11c-40c2-a661-b1b97aa2435f","showTitle":false,"title":""}},"source":["Por defecto, esta consulta sólo mostrará las 1000 primeras filas."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/gk0rG1Qx/db339.png\"></center>"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"c841427d-de72-4fca-b944-0fd511e1311b","showTitle":false,"title":""}},"source":["#### **Crear referencias a archivos**\n","\n","Esta capacidad de consultar directamente archivos y directorios significa que se puede encadenar lógica Spark adicional a consultas contra archivos.\n","\n","Cuando creamos una vista a partir de una consulta sobre una ruta, podemos hacer referencia a esta vista en consultas posteriores."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"a596cd38-4c42-4eff-bee9-53ded2d4e42e","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","CREATE OR REPLACE VIEW event_view\n","AS \n","SELECT * FROM json.`${DA.paths.kafka_events}`"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"367cd78e-7838-43ad-b534-47f9a08fd7e3","showTitle":false,"title":""}},"source":["Siempre que un usuario tenga permiso para acceder a la vista y a la ubicación de almacenamiento subyacente, podrá utilizar esta definición de vista para consultar los datos subyacentes. Esto se aplica a diferentes usuarios del workspace, diferentes notebooks y diferentes clusters."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"61b753ed-59a7-4f57-a684-674ca20b19b5","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","SELECT * FROM event_view"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/vHSTT3w3/db340.png\"></center>"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"3bfba102-0dd0-4625-bded-ce2d98464aa2","showTitle":false,"title":""}},"source":["#### **Crear referencias temporales a archivos**\n","\n","Las vistas temporales permiten asignar a las consultas un nombre que sea más fácil de referenciar en consultas posteriores."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"f71aa6da-85f3-4ec3-895f-6d57e6d3e8ae","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","CREATE OR REPLACE TEMP VIEW events_temp_view\n","AS \n","SELECT * FROM json.`${DA.paths.kafka_events}`"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"e31652bb-2d7a-4d20-a6c2-1ef25f11d67e","showTitle":false,"title":""}},"source":["Las vistas temporales sólo existen para la SparkSession actual. En Databricks, esto significa que están aisladas del notebook, job o consulta DBSQL actual."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"a7c80952-bb95-48c1-8fd1-61353dcb3364","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","SELECT * FROM events_temp_view"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/8zJ56M1D/db341.png\"></center>"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"0f058a92-8eb1-4898-99fe-dbe5834e5dbc","showTitle":false,"title":""}},"source":["#### **Aplicar CTEs como referencia dentro de una consulta**\n","\n","Las Common table expressions (CTE) son perfectas cuando se desea una referencia de corta duración y legible por el usuario a los resultados de una consulta."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"3aa6d0d6-99d7-4cb5-85d6-73870e57af8e","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","WITH cte_json\n","AS (SELECT * FROM json.`${DA.paths.kafka_events}`)\n","SELECT * FROM cte_json"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/wjCBcMvN/db342.png\"></center>"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"4d8face8-489e-4c19-8f8d-575ef7183461","showTitle":false,"title":""}},"source":["Los CTEs sólo aliasan (de 'alias') los resultados de una consulta mientras esa consulta está siendo planificada y ejecutada.\n","\n","Por lo tanto, **la siguiente celda arrojará un error cuando se ejecute**."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"0572ef27-7bf9-465f-a988-46c181bbc12d","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","-- SELECT COUNT(*) FROM cte_json"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/v8t6YrmN/db343.png\"></center>"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"6105472e-d3e5-4253-8d69-fa7e61be9ea3","showTitle":false,"title":""}},"source":["#### **Extraer archivos de texto como strings sin procesar (raw strings)**\n","\n","Al trabajar con archivos basados en texto (que incluyen los formatos JSON, CSV, TSV y TXT), puede utilizar el formato **`text`** para cargar cada línea del archivo como una fila con una columna de cadena denominada **`value`**. Esto puede ser útil cuando las fuentes de datos son propensas a la corrupción y se utilizarán funciones personalizadas de análisis de texto para extraer valores de los campos de texto."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"4f14647d-b156-4c4a-888c-1f72d1fd798b","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","SELECT * FROM text.`${DA.paths.kafka_events}`"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/85DP9YLP/db344.png\"></center>"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"ec29bb03-65cc-4285-98d8-b2808d6e696e","showTitle":false,"title":""}},"source":["#### **Extraer los raw bytes y los metadatos de un archivo**\n","\n","Algunos workflows pueden requerir trabajar con archivos enteros, como cuando se trabaja con imágenes o datos no estructurados. El uso de **`binaryFile`** para consultar un directorio proporcionará metadatos del archivo junto con la representación binaria del contenido del archivo.\n","\n","En concreto, los campos creados indicarán el **`path`**, **`modificationTime`**, **`length`**, y **`content`**."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"9d3d18dd-dfd6-4625-8cc1-350326a9d045","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","SELECT * FROM binaryFile.`${DA.paths.kafka_events}`"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/J0r0DFhd/db345.png\"></center>"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"d8c3573c-54ed-45d0-b010-e9f1adc5d60d","showTitle":false,"title":""}},"source":["Ejecute la siguiente celda para eliminar las tablas y archivos asociados a esta lección."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"92fc7ada-29e2-4e9b-9264-d019c509ea15","showTitle":false,"title":""}},"outputs":[],"source":["%python \n","DA.cleanup()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/MZ5v2zPk/db346.png\"></center>"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"fd3f585a-a0a8-4fde-a4e3-f53aa424032d","showTitle":false,"title":""}},"source":["-sandbox\n","&copy; 2022 Databricks, Inc. All rights reserved.<br/>\n","Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n","<br/>\n","<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":2},"notebookName":"DE 2.1 - Querying Files Directly","widgets":{}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
