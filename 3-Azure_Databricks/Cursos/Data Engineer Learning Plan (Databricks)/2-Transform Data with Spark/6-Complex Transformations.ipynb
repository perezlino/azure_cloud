{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"e300f5a6-ff64-4b6d-a2ec-dd6f2d342e73","showTitle":false,"title":""}},"source":["<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n","  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n","</div>"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"7beca005-5267-41b9-bb0d-cc34f300c446","showTitle":false,"title":""}},"source":["### **Transformación de tipos complejos**\n","\n","Consultar datos tabulares almacenados en el Data Lakehouse con Spark SQL es fácil, eficiente y rápido.\n","\n","Esto se complica a medida que la estructura de datos se vuelve menos regular, cuando es necesario utilizar muchas tablas en una sola consulta o cuando es necesario cambiar drásticamente la forma de los datos. Este notebook introduce una serie de funciones presentes en Spark SQL para ayudar a los ingenieros a completar incluso las transformaciones más complicadas.\n","\n","#### **Objetivos de aprendizaje**\n","Al final de esta lección, deberías ser capaz de:\n","- Utilizar la sintaxis **`.`** y **`:`** para consultar datos anidados\n","- Parsear JSON strings en structs\n","- Aplanar y desempaquetar arrays y structs\n","- Combinar datasets mediante joins\n","- Reformar datos mediante tablas pivot"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"a7859b03-3799-4d02-b59c-77ecd67487f2","showTitle":false,"title":""}},"source":["#### **Run Setup**\n","\n","El setup script creará los datos y declarará los valores necesarios para que el resto de este notebook se ejecute."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"99ac02e0-5d4d-477f-8349-638f63a611db","showTitle":false,"title":""}},"outputs":[],"source":["%run ../Includes/Classroom-Setup-02.5"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"fd246a57-c108-43a1-ac13-f9b09c5b2723","showTitle":false,"title":""}},"source":["#### **Visión general de los datos**\n","\n","La tabla **`events_raw`** se ha registrado con datos que representan una carga útil de Kafka. En la mayoría de los casos, los datos de Kafka serán valores JSON con codificación binaria. \n","\n","Convirtamos **`key`** y **`value`** en strings para ver estos valores en un formato legible por humanos."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"f8ddd8af-3e40-4712-9373-2d0d058b1956","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","CREATE OR REPLACE TEMP VIEW events_strings AS \n","SELECT string(key), string(value) \n","FROM events_raw;\n","\n","SELECT * FROM events_strings"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/MT4ZTL1w/db374.png\"></center>"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"cd72e703-24ae-45a9-acf1-643e6afb25c1","showTitle":false,"title":""}},"outputs":[],"source":["%python\n","from pyspark.sql.functions import col\n","\n","events_stringsDF = (spark\n","    .table(\"events_raw\")\n","    .select(col(\"key\").cast(\"string\"), \n","            col(\"value\").cast(\"string\"))\n","    )\n","display(events_stringsDF)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/MT4ZTL1w/db374.png\"></center>"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"c5c5069e-85a3-4ca7-b2bd-5caeeb9cd3d3","showTitle":false,"title":""}},"source":["#### **Trabajar con datos anidados**\n","\n","La siguiente celda de código consulta las cadenas convertidas para ver un objeto JSON de ejemplo sin campos nulos (lo necesitaremos para la siguiente sección).\n","\n","**NOTA:** Spark SQL tiene funcionalidad incorporada para interactuar directamente con datos anidados almacenados como JSON strings o struct types.\n","- Utiliza la sintaxis **`:`** en las consultas para acceder a los subcampos de las cadenas JSON.\n","- Utiliza la sintaxis **`.`** en las consultas para acceder a los subcampos de los tipos struct."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"ae493605-2e40-42f9-9dcf-430b448d088a","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","SELECT * FROM events_strings \n","WHERE value:event_name = \"finalize\" \n","ORDER BY key LIMIT 1"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/C1TzKMXF/db375.png\"></center>"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"61ceee6d-90e4-4e5c-88b4-6026a16a2373","showTitle":false,"title":""}},"outputs":[],"source":["%python\n","display(events_stringsDF\n","    .where(\"value:event_name = 'finalize'\")\n","    .orderBy(\"key\")\n","    .limit(1)\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/pXGrFJ4c/db376.png\"></center>"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"a52ec45a-5e1c-438b-a2e2-772785f20104","showTitle":false,"title":""}},"source":["Utilicemos el ejemplo del JSON string anterior para derivar el schema, y luego analicemos toda la columna JSON en tipos struct.\n","- **`schema_of_json()`** devuelve el schema derivado de una cadena JSON de ejemplo.\n","- **`from_json()`** analiza una columna que contiene una cadena JSON en un tipo struct utilizando el schema especificado.\n","\n","Después de descomprimir la cadena JSON en un tipo struct, vamos a descomprimir y aplanar todos los campos struct en columnas.\n","- **`*`** unpacking puede ser usado para aplanar structs; **`col_name.*`** extrae los subcampos de **`col_name`** en sus propias columnas."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"c4967d35-83c2-44d5-9b27-7ba96c949265","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","SELECT schema_of_json('{\"device\":\"Linux\",\n","                       \"ecommerce\":{\"purchase_revenue_in_usd\":1075.5,\"total_item_quantity\":1,\"unique_items\":1},\n","                       \"event_name\":\"finalize\",\n","                       \"event_previous_timestamp\":1593879231210816,\n","                       \"event_timestamp\":1593879335779563,\n","                       \"geo\":{\"city\":\"Houston\",\"state\":\"TX\"},\n","                       \"items\":[{\"coupon\":\"NEWBED10\",\n","                                 \"item_id\":\"M_STAN_K\",\n","                                 \"item_name\":\"Standard King Mattress\",\n","                                 \"item_revenue_in_usd\":1075.5,\n","                                 \"price_in_usd\":1195.0,\n","                                 \"quantity\":1}],\n","                       \"traffic_source\":\"email\",\n","                       \"user_first_touch_timestamp\":1593454417513109,\n","                       \"user_id\":\"UA000000106116176\"}') AS schema"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/wvX3R8YD/db378.png\"></center>"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"1fc90e0c-9caf-4ec0-8b22-5fa3a648389c","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","CREATE OR REPLACE TEMP VIEW parsed_events \n","AS SELECT json.* FROM (\n","                        SELECT from_json(value, 'STRUCT<device: STRING, ecommerce: STRUCT<purchase_revenue_in_usd: DOUBLE, total_item_quantity: BIGINT, unique_items: BIGINT>, event_name: STRING, event_previous_timestamp: BIGINT, event_timestamp: BIGINT, geo: STRUCT<city: STRING, state: STRING>, items: ARRAY<STRUCT<coupon: STRING, item_id: STRING, item_name: STRING, item_revenue_in_usd: DOUBLE, price_in_usd: DOUBLE, quantity: BIGINT>>, traffic_source: STRING, user_first_touch_timestamp: BIGINT, user_id: STRING>') AS json \n","                        FROM events_strings);\n","\n","SELECT * FROM parsed_events"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%sql\n","CREATE OR REPLACE TEMP VIEW parsed_events \n","AS SELECT json.* FROM (\n","                        SELECT from_json(value, schema_of_json('{\"device\":\"Linux\",\"ecommerce\":{\"purchase_revenue_in_usd\":1075.5,\"total_item_quantity\":1,\"unique_items\":1},\"event_name\":\"finalize\",\"event_previous_timestamp\":1593879231210816,\"event_timestamp\":1593879335779563,\"geo\":{\"city\":\"Houston\",\"state\":\"TX\"},\"items\":[{\"coupon\":\"NEWBED10\",\"item_id\":\"M_STAN_K\",\"item_name\":\"Standard King Mattress\",\"item_revenue_in_usd\":1075.5,\"price_in_usd\":1195.0,\"quantity\":1}],\"traffic_source\":\"email\",\"user_first_touch_timestamp\":1593454417513109,\"user_id\":\"UA000000106116176\"}')) AS json \n","                        FROM events_strings);\n","\n","SELECT * FROM parsed_events"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/3xzwLJKg/db377.png\"></center>"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"b2facc37-4d8b-4be2-aaa7-1dbddfdd916b","showTitle":false,"title":""}},"outputs":[],"source":["%python\n","from pyspark.sql.functions import from_json, schema_of_json\n","\n","json_string = \"\"\"\n","{\"device\":\"Linux\",\"ecommerce\":{\"purchase_revenue_in_usd\":1047.6,\"total_item_quantity\":2,\"unique_items\":2},\"event_name\":\"finalize\",\"event_previous_timestamp\":1593879787820475,\"event_timestamp\":1593879948830076,\"geo\":{\"city\":\"Huntington Park\",\"state\":\"CA\"},\"items\":[{\"coupon\":\"NEWBED10\",\"item_id\":\"M_STAN_Q\",\"item_name\":\"Standard Queen Mattress\",\"item_revenue_in_usd\":940.5,\"price_in_usd\":1045.0,\"quantity\":1},{\"coupon\":\"NEWBED10\",\"item_id\":\"P_DOWN_S\",\"item_name\":\"Standard Down Pillow\",\"item_revenue_in_usd\":107.10000000000001,\"price_in_usd\":119.0,\"quantity\":1}],\"traffic_source\":\"email\",\"user_first_touch_timestamp\":1593583891412316,\"user_id\":\"UA000000106459577\"}\n","\"\"\"\n","parsed_eventsDF = (events_stringsDF\n","    .select(from_json(\"value\", schema_of_json(json_string)).alias(\"json\"))\n","    .select(\"json.*\")\n",")\n","\n","display(parsed_eventsDF)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/rwDmCtLV/db379.png\"></center>"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"6678c52f-93ca-47ac-ade7-a639577d753c","showTitle":false,"title":""}},"source":["#### **Manipular Arrays**\n","\n","Spark SQL tiene una serie de funciones para manipular array data, incluyendo las siguientes:\n","- **`explode()`** separa los elementos de un array en múltiples filas; esto crea una nueva fila para cada elemento.\n","- **`size()`** proporciona un recuento del número de elementos de un array para cada fila.\n","\n","El código siguiente descompone (explodes) el campo **`items`** (un array de structs) en múltiples filas y muestra los eventos que contienen arrays con 3 o más elementos."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"4708a3b8-caba-488b-ae89-3a3de0ed6035","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","CREATE OR REPLACE TEMP VIEW exploded_events AS\n","SELECT *, explode(items) AS item\n","FROM parsed_events;\n","\n","SELECT * FROM exploded_events WHERE size(items) > 2"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/zvqvntq6/db380.png\"></center>\n","<center><img src=\"https://i.postimg.cc/5tv2Dd0D/db381.png\"></center>\n","<center><img src=\"https://i.postimg.cc/3N9R9XRR/db382.png\"></center>\n","<center><img src=\"https://i.postimg.cc/FFx794Z4/db383.png\"></center>"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"c822ee19-af32-47f7-a93f-a5b23c139ad4","showTitle":false,"title":""}},"outputs":[],"source":["%python\n","from pyspark.sql.functions import explode, size\n","\n","exploded_eventsDF = (parsed_eventsDF\n","    .withColumn(\"item\", explode(\"items\"))\n",")\n","\n","display(exploded_eventsDF.where(size(\"items\") > 2))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/Pxj5j3vJ/db384.png\"></center>"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"4c7cb77a-f7d7-4230-98c0-5498309b0217","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","DESCRIBE exploded_events"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"b5ca821d-1d96-401b-8feb-2ebf0a61c6d8","showTitle":false,"title":""}},"source":["El siguiente código combina transformaciones de arrays para crear una tabla que muestra la colección única de actions y los items en el carrito de un usuario.\n","- **`collect_set()`** recoge valores únicos para un campo, incluyendo campos dentro de arrays.\n","- **`flatten()`** combina múltiples arrays en un único array.\n","- **`array_distinct()`** elimina los elementos duplicados de un array."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"f40f93b9-f9c7-4531-b4c5-5ed28654da1b","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","SELECT user_id,\n","  collect_set(event_name) AS event_history,\n","  array_distinct(flatten(collect_set(items.item_id))) AS cart_history\n","FROM exploded_events\n","GROUP BY user_id"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/fLfTTcYK/db385.png\"></center>"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"a551189c-8ece-43c5-a665-98a38d78ab13","showTitle":false,"title":""}},"outputs":[],"source":["%python\n","\n","from pyspark.sql.functions import array_distinct, collect_set, flatten\n","\n","display(exploded_eventsDF\n","    .groupby(\"user_id\")\n","    .agg(collect_set(\"event_name\").alias(\"event_history\"),\n","            array_distinct(flatten(collect_set(\"items.item_id\"))).alias(\"cart_history\"))\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/90XX4Dpj/db386.png\"></center>"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"16e74b05-e7aa-4b89-991b-837337bc6b9e","showTitle":false,"title":""}},"source":["#### **Join Tables**\n","\n","Spark SQL soporta operaciones estándar **`JOIN`** (inner, outer, left, right, anti, cross, semi).  \n","Aquí joineamos el dataset de eventos explotados (exploded events dataset) con una tabla lookup para obtener el nombre estándar del ítem impreso."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"8e3c1510-90c8-450e-89c9-eac9b34bfd68","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","CREATE OR REPLACE TEMP VIEW item_purchases AS\n","\n","SELECT * \n","FROM (SELECT *, explode(items) AS item FROM sales) a\n","INNER JOIN item_lookup b\n","ON a.item.item_id = b.item_id;\n","\n","SELECT * FROM item_purchases"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/T1kdnT75/db387.png\"></center>\n","<center><img src=\"https://i.postimg.cc/2jT8sxkj/db388.png\"></center>\n","<center><img src=\"https://i.postimg.cc/KvzvxgjP/db389.png\"></center>\n","<center><img src=\"https://i.postimg.cc/SNvQsNYw/db390.png\"></center>"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"0c79b1f3-0a30-4fc2-98c3-31615f82f466","showTitle":false,"title":""}},"outputs":[],"source":["%python\n","exploded_salesDF = (spark\n","    .table(\"sales\")\n","    .withColumn(\"item\", explode(\"items\"))\n",")\n","\n","itemsDF = spark.table(\"item_lookup\")\n","\n","item_purchasesDF = (exploded_salesDF\n","    .join(itemsDF, exploded_salesDF.item.item_id == itemsDF.item_id)\n",")\n","\n","display(item_purchasesDF)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/W1qNJLMt/db391.png\"></center>"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"75dbeb34-28db-47b8-9bd7-df20c5492b9f","showTitle":false,"title":""}},"source":["#### **Tablas Pivot**\n","\n","Podemos utilizar **`PIVOT`** para ver los datos desde diferentes perspectivas mediante la rotación de valores únicos en una columna pivote especificada en múltiples columnas basadas en una función agregada.\n","- La cláusula **`PIVOT`** sigue al nombre de la tabla o subconsulta especificada en una cláusula **`FROM`**, que es la entrada para la tabla pivot.\n","- Los valores únicos de la columna pivotante se agrupan y agregan utilizando la expresión de agregación proporcionada, creando una columna independiente para cada valor único en la tabla pivotante resultante.\n","\n","La siguiente celda de código utiliza **`PIVOT`** para aplanar la información de compra de ítems contenida en varios campos derivados del dataset **`sales`**. Este formato de datos aplanado puede ser útil para la creación de dashboards, pero también para aplicar algoritmos de machine learning para inferencia o predicción."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"14f70ad2-6a98-48aa-a83a-9a6347b5e559","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","SELECT *\n","FROM item_purchases\n","PIVOT (\n","  sum(item.quantity) FOR item_id IN (\n","    'P_FOAM_K',\n","    'M_STAN_Q',\n","    'P_FOAM_S',\n","    'M_PREM_Q',\n","    'M_STAN_F',\n","    'M_STAN_T',\n","    'M_PREM_K',\n","    'M_PREM_F',\n","    'M_STAN_K',\n","    'M_PREM_T',\n","    'P_DOWN_S',\n","    'P_DOWN_K')\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<center><img src=\"https://i.postimg.cc/6Qs9rj0c/db392.png\"></center>\n","<center><img src=\"https://i.postimg.cc/1tBsZ9Z7/db395.png\"></center>\n","<center><img src=\"https://i.postimg.cc/V6mmTJ2b/db394.png\"></center>\n","<center><img src=\"https://i.postimg.cc/s2p3wYHr/db393.png\"></center>"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"aa49fa7f-0276-42c3-9514-83731e303e3b","showTitle":false,"title":""}},"outputs":[],"source":["%python\n","transactionsDF = (item_purchasesDF\n","    .groupBy(\"order_id\", \n","        \"email\",\n","        \"transaction_timestamp\", \n","        \"total_item_quantity\", \n","        \"purchase_revenue_in_usd\", \n","        \"unique_items\",\n","        \"items\",\n","        \"item\",\n","        \"name\",\n","        \"price\")\n","    .pivot(\"item_id\")\n","    .sum(\"item.quantity\")\n",")\n","display(transactionsDF)"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"7acc98aa-5fa8-4dac-ba92-588cd7db7915","showTitle":false,"title":""}},"source":["Ejecute la siguiente celda para eliminar las tablas y archivos asociados a esta lección."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"fbffa30d-dbb3-478b-a429-ff365264e280","showTitle":false,"title":""}},"outputs":[],"source":["%python\n","DA.cleanup()"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"08ecbca1-6707-4b62-b7ae-d040b9a4bca1","showTitle":false,"title":""}},"source":["-sandbox\n","&copy; 2022 Databricks, Inc. All rights reserved.<br/>\n","Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n","<br/>\n","<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":2},"notebookName":"DE 2.5 - Complex Transformations","widgets":{}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
