{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) **Hive Metastore**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a aprender sobre los objetos de datos de Spark, como bases de datos, tablas y vistas. Para tener una mejor comprensión, primero tenemos que entender el papel del **Hive metastore** en todo esto. Como hemos visto, nuestros datos se almacenan en nuestro Data Lake como archivos de distintos tipos como CSV, JSON y Parquet. Para que Spark trate estos datos como tablas y columnas, necesitamos registrar estos datos en un Metastore. Metastore no es más que un storage para almacenar los metadatos sobre los archivos de datos, por ejemplo, cosas como la ubicación del archivo, el formato de los datos, nombres de columnas, etc. Spark utiliza para ello el Metastore proporcionado por Apache Hive Project, que recibe el nombre de Hive Metastore. Hive Metastore es el metastore más utilizado en el espacio Data Lake. A la hora de elegir el almacenamiento para Hive Metastore, tenemos una opción, podemos elegir el metastore gestionado por defecto por Databricks o la opción de almacenamiento externo propio. Así que puedes elegir entre Azure SQL, mySQL, MariaDB y algunos otros. Una vez registradas nuestras tablas en el Hive metastore, podemos utilizar Spark SQL para acceder a estas tablas como lo haríamos en una base de datos relacional. Sólo para resumir, los datos se almacenan normalmente en un almacenamiento de objetos, que es ADLS, en nuestro caso. El Hive metastore guarda la información sobre el archivo, como la ubicación, el nombre del archivo, la columna de la tabla, etc. Al ejecutar el comando Spark SQL, Spark utiliza el metastore para aplicar el schema y acceder a los archivos en consecuencia, como si estuviéramos accediendo a cualquier tabla relacional. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/q7CZpF6J/db87.png\"></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos ahora cómo organiza Databricks las bases de datos, las tablas y las vistas. Un Databricks workspace puede tener un número de bases de datos. También se conocen como schemas dentro de una base de datos, pueden tener un número de tablas y vistas. Las tablas son básicamente estructuras dadas a los datos almacenados en un almacenamiento de objetos, como dijimos, ADLS es nuestro almacenamiento de objetos. Hay dos tipos de tablas en Spark. La primera se llama \"managed table\" (tabla gestionada) y la otra se llama \"external table\" (tabla externa) o \"unmanaged table\" (tabla no gestionada). En el caso de la tabla gestionada, Spark mantiene tanto los metadatos en el Hive metastore como también los archivos de datos asociados a una tabla, que en nuestro caso se almacena en ADLS. En el caso de las tablas externas, Spark sólo gestiona los metadatos y nosotros los archivos de datos. Lo que quiero decir con esto es que para las tablas externas, nosotros especificamos la ubicación de los archivos de datos y Spark no lo decide por sí mismo. Además, las principales propiedades de una tabla externa son que al eliminarla no se borran los archivos, mientras que en el caso de una tabla gestionada, se borran los archivos al mismo tiempo que se elimina la tabla. Las vistas se pueden construir sobre las tablas con una selección de datos. Por ejemplo, puedes aplicar un filtro a una tabla o puedes seleccionar sólo un cierto número de columnas y luego crear una vista con esa información. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/RFhYj01Y/db88.png\"></center>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
